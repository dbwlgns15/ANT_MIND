{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e52c1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "import pickle\n",
    "from konlpy.tag import Okt\n",
    "from bs4 import BeautifulSoup\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9707ebc6",
   "metadata": {},
   "source": [
    "# LSTM 학습 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90f10e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code(symbol):\n",
    "    krx = pd.read_csv('./src/krx_code.csv')\n",
    "    krx = krx.set_index('한글 종목약명')\n",
    "    try:\n",
    "        code = krx.at[symbol,'단축코드']\n",
    "        return code\n",
    "    except:\n",
    "        print('종목명을 다시 확인해주세요.')\n",
    "        return 0\n",
    "\n",
    "def get_comment_df(symbol,page):\n",
    "    if get_code(symbol) == 0:\n",
    "        return\n",
    "    code = get_code(symbol)\n",
    "    date_list, comment_list, view_list, good_list, bad_list = [], [], [], [], []\n",
    "    for i in range(1,page+1):\n",
    "        url = f'https://finance.naver.com/item/board.naver?code={code}&page={i}'\n",
    "        headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36 Edg/100.0.1185.50'}\n",
    "        res = requests.get(url, headers = headers)\n",
    "        bs = BeautifulSoup(res.text, 'html.parser')\n",
    "        for j in range(20):\n",
    "            try:\n",
    "                root = bs.find('div',{'class':'section inner_sub'}).find_all('tr',{'onmouseover':'mouseOver(this)'})[j].text.split('\\n')\n",
    "                date_list.append(root[1].split()[0].replace('.','-'))\n",
    "                if len(root) == 14: # 답글\n",
    "                    comment_list.append('답글:'+root[4])\n",
    "                    view_list.append(root[10])\n",
    "                    good_list.append(root[11])\n",
    "                    bad_list.append(root[12])          \n",
    "                elif len(root) == 13: # 기본\n",
    "                    comment_list.append(root[3])\n",
    "                    view_list.append(root[9])\n",
    "                    good_list.append(root[10])\n",
    "                    bad_list.append(root[11])\n",
    "                else: # 에러\n",
    "                    comment_list.append('error')\n",
    "                    view_list.append(0)\n",
    "                    good_list.append(0)\n",
    "                    bad_list.append(0)   \n",
    "            except: # 에러\n",
    "                date_list.append('error')\n",
    "                comment_list.append('error')\n",
    "                view_list.append(0)\n",
    "                good_list.append(0)\n",
    "                bad_list.append(0)   \n",
    "        print(f'\\r{i}페이지 크롤링 완료.',end='')   \n",
    "    df = pd.DataFrame()\n",
    "    df['날짜'] = date_list\n",
    "    df['댓글'] = comment_list\n",
    "    df['조회수'] = view_list\n",
    "    df['좋아요'] = good_list\n",
    "    df['싫어요'] = bad_list\n",
    "    return df\n",
    "\n",
    "def preprocess_df(symbol,page):\n",
    "    if get_code(symbol) == 0:\n",
    "        return \n",
    "    df = get_comment_df(symbol,page)\n",
    "    df = df[df['댓글'] != 'error'] \n",
    "    df = df.dropna() \n",
    "    df['한글댓글'] = df['댓글'].str.replace('\\[삭제된 게시물의 답글\\]',' ') \n",
    "    df['한글댓글'] = df['한글댓글'].str.replace('답글:',' ')\n",
    "    df['한글댓글'] = df['한글댓글'].str.replace('[^가-힣]',' ').str.replace(' +',' ').str.strip() \n",
    "    df = df[df['한글댓글'] != ''] \n",
    "    df = df.reset_index(drop=True) \n",
    "    return df\n",
    "\n",
    "def preprocess_okt_df(symbol,page):\n",
    "    if get_code(symbol) == 0:\n",
    "        return\n",
    "    df = preprocess_df(symbol,page)\n",
    "    okt = Okt()\n",
    "    tag_list = ['Noun','Verb','Adjective','VerbPrefix']\n",
    "    tokenized_data = []\n",
    "    print()\n",
    "    for i in range(df.shape[0]):\n",
    "        tokenized_sentence = okt.pos(df['한글댓글'][i], stem=True) # 토큰화\n",
    "        tag_checked_sentence = []\n",
    "        for j in tokenized_sentence:\n",
    "            x,y = j\n",
    "            if y in tag_list:\n",
    "                tag_checked_sentence.append(x)\n",
    "        tokenized_data.append(tag_checked_sentence)\n",
    "        print(f'\\r{i+1}개 형태소분석 완료.',end='')\n",
    "    df['토큰화댓글'] = tokenized_data\n",
    "    df = df[df['토큰화댓글'].str.len() > 1]\n",
    "    df = df.reset_index(drop=True) \n",
    "    return df\n",
    "\n",
    "greed_word = ['매수','사','사다','사라','사면','사고','줍다','들어오다','들어가다','타다','수급','매집','올라타다' # 주식 구매 단어\n",
    "              ,'탑승','불나방','담다'\n",
    "              ,'오르다','올라가다','올리다','올려주다','올린다','오름','올려놓다','오른','상향' # 주식 가격 상승 단어\n",
    "              ,'양봉','상방','상승','살아나다','양전','상한','반등','폭등','퍽등','급등'\n",
    "              ,'탐욕','찬티','좋다','간다','가다','가즈','싸다','익절','제발','최고','돌파','수익','위대하다','먹다' # 탐욕 단어\n",
    "              ,'기회','호재','감사','감사하다','대박','대단하다','승리','찬양','믿다','회복','갓','부활','영차','개꿀']\n",
    "fear_word = ['공매도','공매','매도','팔','파다','팔다','팔고','팔면','던지다','털다','탈출','튀다','튀어','설거지' # 주식 판매 단어\n",
    "             ,'손절','버리다'\n",
    "             ,'떨어지다','떨구다','빠지다','하락','폭락','떡락','조정','급락','음봉','하방','폭포수','음전' # 주식 가격 하락 단어\n",
    "             ,'반토막','내리다','내려오다','깨지다','대퍽락','나락','붕괴','추락'\n",
    "             ,'공포','안티','망하다','물리다','끝나다','손해','폭망','거품','무섭다','자살','악재','상폐','개미지옥' # 공포 단어\n",
    "             ,'시발','염병','욕','짜증나다','걸레','어휴','개','놈','아가리','빡치다','지랄','손실','버티다','존버'\n",
    "             ,'개관','주가조작','쓰레기','죽다','패닉','홀딩','바닥','흑우','추매','추미애']\n",
    "\n",
    "def preprocess_label_df(symbol,page):\n",
    "    if get_code(symbol) == 0:\n",
    "        return\n",
    "    df = preprocess_okt_df(symbol,page)\n",
    "    df['공포탐욕'] = 0\n",
    "    label_list = df['공포탐욕'].to_list()\n",
    "    token_list = df['토큰화댓글'].to_list()\n",
    "    print()\n",
    "    for i in range(len(token_list)):\n",
    "        x = token_list[i]\n",
    "        for word in x:\n",
    "            if word in greed_word:\n",
    "                label_list[i] += 1\n",
    "            if word in fear_word:\n",
    "                label_list[i] -= 1\n",
    "        if label_list[i] == 0:\n",
    "            label_list[i] = 'm'\n",
    "        elif label_list[i] > 0:\n",
    "            label_list[i] = 1\n",
    "        elif label_list[i] < 0:\n",
    "            label_list[i] = 0\n",
    "        print(f'\\r{i+1}개 라벨링 완료.',end='')\n",
    "    df['공포탐욕'] = label_list\n",
    "    df.to_csv(f'./src/네이버종토방댓글_{symbol}_{page}_전처리.csv', index=False)\n",
    "    return df\n",
    "\n",
    "def make_train(symbol,page):\n",
    "    if get_code(symbol) == 0:\n",
    "        return\n",
    "    train = pd.read_csv('./src/train.csv')\n",
    "    train = train[['토큰화댓글','공포탐욕']]\n",
    "    df = preprocess_label_df(symbol,page)\n",
    "    df = df[['토큰화댓글','공포탐욕']]\n",
    "    df = df.append(train)\n",
    "    df = df.astype(str)\n",
    "    df = df.drop_duplicates('토큰화댓글')\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def make_train_token(symbol,page):\n",
    "    if get_code(symbol) == 0:\n",
    "        return\n",
    "    df = make_train(symbol,page)\n",
    "    print()\n",
    "    print('토큰화 진행중..',end='')\n",
    "    tokenizer = Tokenizer(num_words=40000, oov_token = True)\n",
    "    tokenizer.fit_on_texts(df['토큰화댓글'])\n",
    "    df['토큰'] = tokenizer.texts_to_sequences(df['토큰화댓글'])\n",
    "    print('\\r토큰화 완료.    ')\n",
    "    with open('./src/tokenizer.pickle', 'wb') as handle:\n",
    "        pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    df = df[df['공포탐욕'] != 'm']\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.to_csv(f'./src/train.csv', index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b546d140",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10페이지 크롤링 완료.\n",
      "197개 형태소분석 완료.\n",
      "169개 라벨링 완료.\n",
      "토큰화 완료.    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>토큰화댓글</th>\n",
       "      <th>공포탐욕</th>\n",
       "      <th>토큰</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['코스피지수', '올리다']</td>\n",
       "      <td>1</td>\n",
       "      <td>[1845, 43]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['물렷는데', '회복', '가능하다', '요']</td>\n",
       "      <td>1</td>\n",
       "      <td>[7929, 387, 813, 109]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['떨어지다', '하다', '주식', '많다', '않다']</td>\n",
       "      <td>0</td>\n",
       "      <td>[13, 2, 18, 93, 125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['자사', '소각', '하다', '주가', '올려주다']</td>\n",
       "      <td>1</td>\n",
       "      <td>[2081, 2187, 2, 54, 335]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['추가', '매수', '하다']</td>\n",
       "      <td>1</td>\n",
       "      <td>[241, 6, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75408</th>\n",
       "      <td>['낼', '셀트', '가다', '삐', '끄다']</td>\n",
       "      <td>1</td>\n",
       "      <td>[113, 524, 4, 2657, 229]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75409</th>\n",
       "      <td>['셀', '틀다', '낼', '폭등']</td>\n",
       "      <td>1</td>\n",
       "      <td>[950, 1145, 113, 94]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75410</th>\n",
       "      <td>['여기', '털리다', '빠가사리', '나가다', '죽다']</td>\n",
       "      <td>0</td>\n",
       "      <td>[136, 353, 14407, 185, 126]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75411</th>\n",
       "      <td>['어차피', '또', '폭등', '하다', '떨다', '필요', '있다', '회주']</td>\n",
       "      <td>1</td>\n",
       "      <td>[292, 72, 94, 2, 522, 1440, 31, 2939]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75412</th>\n",
       "      <td>['오늘', '물리다', '생각', '하다', '사람', '도대체']</td>\n",
       "      <td>0</td>\n",
       "      <td>[5, 46, 144, 2, 66, 732]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75413 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  토큰화댓글 공포탐욕  \\\n",
       "0                                      ['코스피지수', '올리다']    1   \n",
       "1                           ['물렷는데', '회복', '가능하다', '요']    1   \n",
       "2                      ['떨어지다', '하다', '주식', '많다', '않다']    0   \n",
       "3                      ['자사', '소각', '하다', '주가', '올려주다']    1   \n",
       "4                                    ['추가', '매수', '하다']    1   \n",
       "...                                                 ...  ...   \n",
       "75408                      ['낼', '셀트', '가다', '삐', '끄다']    1   \n",
       "75409                            ['셀', '틀다', '낼', '폭등']    1   \n",
       "75410                ['여기', '털리다', '빠가사리', '나가다', '죽다']    0   \n",
       "75411  ['어차피', '또', '폭등', '하다', '떨다', '필요', '있다', '회주']    1   \n",
       "75412            ['오늘', '물리다', '생각', '하다', '사람', '도대체']    0   \n",
       "\n",
       "                                          토큰  \n",
       "0                                 [1845, 43]  \n",
       "1                      [7929, 387, 813, 109]  \n",
       "2                       [13, 2, 18, 93, 125]  \n",
       "3                   [2081, 2187, 2, 54, 335]  \n",
       "4                                [241, 6, 2]  \n",
       "...                                      ...  \n",
       "75408               [113, 524, 4, 2657, 229]  \n",
       "75409                   [950, 1145, 113, 94]  \n",
       "75410            [136, 353, 14407, 185, 126]  \n",
       "75411  [292, 72, 94, 2, 522, 1440, 31, 2939]  \n",
       "75412               [5, 46, 144, 2, 66, 732]  \n",
       "\n",
       "[75413 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_train_token('NAVER',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ae73b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰화 완료.    \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "df = pd.read_csv('./src/labeled_comment.csv')\n",
    "def make_train_token(df):\n",
    "    print('토큰화 진행중..',end='')\n",
    "    tokenizer = Tokenizer(num_words=40000, oov_token = True)\n",
    "    tokenizer.fit_on_texts(df['토큰화 댓글'])\n",
    "    df['토큰'] = tokenizer.texts_to_sequences(df['토큰화 댓글'])\n",
    "    print('\\r토큰화 완료.    ')\n",
    "    with open('./src/tokenizer.pickle', 'wb') as handle:\n",
    "        pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    df = df[df['공포탐욕'] != 'm']\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.to_csv('./src/train.csv', index=False)\n",
    "    return df\n",
    "df = make_train_token(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2814f6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기:  (107714, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>댓글</th>\n",
       "      <th>정제된 댓글</th>\n",
       "      <th>토큰화 댓글</th>\n",
       "      <th>공포탐욕</th>\n",
       "      <th>토큰</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>안티 살발하다</td>\n",
       "      <td>안티 살발하다</td>\n",
       "      <td>['안티', '살발']</td>\n",
       "      <td>0</td>\n",
       "      <td>[88, 12994]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>카카오는 왜 이렇게 국민들의 안티기업이 ...</td>\n",
       "      <td>카카오는 왜 이렇게 국민들의 안티기업이</td>\n",
       "      <td>['카카오', '왜', '국민', '안티', '기업']</td>\n",
       "      <td>0</td>\n",
       "      <td>[3, 23, 54, 88, 90]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>팔아처묵은 개미새0 말참많은내</td>\n",
       "      <td>팔아처묵은 개미새 말참많은내</td>\n",
       "      <td>['팔', '처', '묵다', '개미', '새', '말', '차다', '많다']</td>\n",
       "      <td>0</td>\n",
       "      <td>[278, 289, 1384, 8, 977, 44, 221, 83]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>내일 카카오 -14프로 내리는날</td>\n",
       "      <td>내일 카카오 프로 내리는날</td>\n",
       "      <td>['내일', '카카오', '프로', '내리다', '날']</td>\n",
       "      <td>0</td>\n",
       "      <td>[36, 3, 93, 194, 115]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>버핏은 애플 더 담았단다</td>\n",
       "      <td>버핏은 애플 더 담았단다</td>\n",
       "      <td>['버핏', '애플', '더', '담다']</td>\n",
       "      <td>1</td>\n",
       "      <td>[3549, 641, 40, 242]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          댓글                 정제된 댓글  \\\n",
       "0                    안티 살발하다                안티 살발하다   \n",
       "1  카카오는 왜 이렇게 국민들의 안티기업이 ...  카카오는 왜 이렇게 국민들의 안티기업이   \n",
       "2           팔아처묵은 개미새0 말참많은내        팔아처묵은 개미새 말참많은내   \n",
       "3          내일 카카오 -14프로 내리는날         내일 카카오 프로 내리는날   \n",
       "4              버핏은 애플 더 담았단다          버핏은 애플 더 담았단다   \n",
       "\n",
       "                                         토큰화 댓글 공포탐욕  \\\n",
       "0                                  ['안티', '살발']    0   \n",
       "1                ['카카오', '왜', '국민', '안티', '기업']    0   \n",
       "2  ['팔', '처', '묵다', '개미', '새', '말', '차다', '많다']    0   \n",
       "3               ['내일', '카카오', '프로', '내리다', '날']    0   \n",
       "4                       ['버핏', '애플', '더', '담다']    1   \n",
       "\n",
       "                                      토큰  \n",
       "0                            [88, 12994]  \n",
       "1                    [3, 23, 54, 88, 90]  \n",
       "2  [278, 289, 1384, 8, 977, 44, 221, 83]  \n",
       "3                  [36, 3, 93, 194, 115]  \n",
       "4                   [3549, 641, 40, 242]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('데이터 크기: ',df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65df512a",
   "metadata": {},
   "source": [
    "# LSTM 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af222ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def train_LSTM():\n",
    "    df = pd.read_csv('./src/train.csv')\n",
    "    train = pad_sequences(df['토큰'], maxlen=15)\n",
    "    \n",
    "    label = df['공포탐욕']\n",
    "    encoder = LabelEncoder()\n",
    "    batch_size = label.shape[0]\n",
    "    input_dim = 1\n",
    "    label = encoder.fit_transform(label)\n",
    "    label = np.reshape(label, (batch_size, input_dim))\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(40000, 128))\n",
    "    model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    hist = model.fit(train, label, batch_size=32, epochs=5)\n",
    "    model.save('./src/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1150ae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_LSTM()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
